"""
Enhanced Web Search Integration

Orchestrates web search components:
1. Search decision (when to search) - SearchDecisionEngine
2. URL handling (explicit URLs) - URLFetcher  
3. Tavily API integration (query optimization + result ranking)
4. Response formatting (citations)

This module provides a unified interface for transparent web search.

Note: Query optimization and result ranking delegated to Tavily API for simplicity.
"""

import requests
import os
from typing import Dict, List, Optional, Tuple
from dotenv import load_dotenv

from server.search import (
    SearchDecisionEngine,
    URLFetcher
)
from server.search import response_generator
from server.query_handler import query_model

# Load environment variables
env_path = os.path.join(os.path.dirname(__file__), '.env.local')
load_dotenv(dotenv_path=env_path)
load_dotenv()

# Tavily API Configuration
TAVILY_API_BASE_URL = "https://api.tavily.com/search"
TAVILY_API_KEY = os.getenv("TAVILY_API_KEY", "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")


class EnhancedWebSearch:
    """Main orchestrator for enhanced web search with automatic decision-making."""

    def __init__(self):
        """Initialize search components."""
        self.decision_engine = SearchDecisionEngine()
        self.url_fetcher = URLFetcher(timeout=10)

    async def search_and_answer(
        self,
        user_query: str,
        conversation_history: Optional[List[Dict]] = None,
        force_search: bool = False,
        **kwargs
    ):
        """
        Main entry point: automatically decide if search is needed and generate response.

        Args:
            user_query: User's question
            conversation_history: Previous conversation messages
            force_search: Force web search even if decision says no
            **kwargs: Additional Tavily API parameters

        Returns:
            Dict with:
                - response: Generated answer
                - search_triggered: Whether web search was used
                - decision: Search decision details
                - sources: List of sources used (if any)
                - method: 'web_search', 'url_fetch', or 'knowledge'
        """
        # Step 1: Check for explicit URLs in query
        urls = self.url_fetcher.extract_urls(user_query)
        if urls:
            return await self._handle_explicit_urls(user_query, urls, conversation_history)

        # Step 2: Decide if web search is needed
        if not force_search:
            decision = await self.decision_engine.should_search(user_query, conversation_history)
        else:
            decision = {
                'needs_search': True,
                'reasoning': 'Force search requested',
                'confidence': 1.0,
                'method': 'forced'
            }

        # Step 3: Execute based on decision
        if decision['needs_search']:
            return await self._handle_web_search(
                user_query,
                conversation_history,
                decision,
                **kwargs
            )
        else:
            # No search needed - answer from knowledge
            return {
                'response': None,  # Will be generated by regular query handler
                'search_triggered': False,
                'decision': decision,
                'sources': [],
                'method': 'knowledge'
            }

    async def _handle_explicit_urls(
        self,
        user_query: str,
        urls: List[str],
        conversation_history: Optional[List[Dict]]
    ):
        """
        Handle queries with explicit URLs.

        Returns:
            Response dict with URL content
        """
        # Fetch URLs
        url_results = self.url_fetcher.fetch_multiple_urls(urls)

        # Check for errors
        successful_fetches = [r for r in url_results if r['success']]

        if not successful_fetches:
            # All fetches failed
            error_messages = [r['error'] for r in url_results if r.get('error')]
            error_msg = "Failed to fetch URLs: " + "; ".join(error_messages[:2])
            return {
                'response': f"I wasn't able to access those pages. {error_msg}",
                'search_triggered': False,
                'decision': {'needs_search': False, 'reasoning': 'URL fetch failed'},
                'sources': [],
                'method': 'url_fetch_failed'
            }

        # Generate response with URL content
        prompt = response_generator.build_prompt(
            user_query,
            search_results=None,
            url_content=successful_fetches
        )

        system_prompt = response_generator.build_system_prompt()

        # Query LLM (await the async call)
        llm_response = await query_model(
            user_prompt=f"{system_prompt}\n\n{prompt}",
            model_name='llama3.2:3b',
            stream=False,
            conversation_history=conversation_history
        )

        # Build sources list
        sources = [
            {'url': r['url'], 'title': r['title']}
            for r in successful_fetches
        ]

        return {
            'response': llm_response,
            'search_triggered': False,
            'decision': {'needs_search': False, 'reasoning': 'Explicit URLs provided'},
            'sources': sources,
            'method': 'url_fetch'
        }

    async def _handle_web_search(
        self,
        user_query: str,
        conversation_history: Optional[List[Dict]],
        decision: Dict,
        **kwargs
    ):
        """
        Handle web search queries.

        Returns:
            Response dict with search results
        """
        # Step 1: Execute Tavily search directly (it handles query optimization internally)
        print(f"üîç Executing Tavily search for: {user_query}")
        results = self._execute_tavily_search(user_query, **kwargs)

        print(f"üìä Received {len(results)} results from Tavily")

        if not results:
            return {
                'response': "I couldn't find recent information on this topic. Let me answer based on my training knowledge.",
                'search_triggered': True,
                'decision': decision,
                'sources': [],
                'method': 'web_search_no_results'
            }

        # Step 2: Format results for LLM (Tavily already ranked them)
        context = self._format_search_context(user_query, results)

        # Step 3: Generate response with search context
        system_prompt = """You are a helpful AI assistant with access to web search.

When search results are provided in <search_results> tags:
1. Use them to give accurate, up-to-date answers
2. Cite sources naturally: "According to X, ...", "X reports that ..."
3. Prioritize recent, authoritative sources
4. Don't quote more than 15 words - paraphrase instead
5. Synthesize information from multiple sources when relevant"""

        full_prompt = f"{system_prompt}\n\n{context}"

        # Query LLM with async support
        llm_response = await query_model(
            user_prompt=full_prompt,
            model_name='llama3.2:3b',
            stream=False,
            conversation_history=conversation_history
        )

        # Build sources list from top results
        sources = [
            {
                'url': r['url'],
                'title': r['title']
            }
            for r in results[:3]  # Top 3
        ]

        return {
            'response': llm_response,
            'search_triggered': True,
            'decision': decision,
            'sources': sources,
            'method': 'web_search',
            'num_results': len(results)
        }

    def _format_search_context(self, user_query: str, results: List[Dict]) -> str:
        """
        Format search results as context for LLM.

        Args:
            user_query: Original user query
            results: Search results from Tavily

        Returns:
            Formatted context string
        """
        context_parts = ["<search_results>"]

        for idx, result in enumerate(results, 1):
            url = result.get('url', '')
            title = result.get('title', 'No title')
            content = result.get('content', '')

            # Limit content length
            if len(content) > 1000:
                content = content[:1000] + "..."

            context_parts.append(f"""
<result index="{idx}">
<url>{url}</url>
<title>{title}</title>
<content>{content}</content>
</result>""")

        context_parts.append("</search_results>")
        context_parts.append(f"\nAnswer this question using the search results above:\n{user_query}")

        return "\n".join(context_parts)

    def _execute_tavily_search(self, query: str, **kwargs) -> List[Dict]:
        """
        Execute Tavily search API call.

        Args:
            query: Search query
            **kwargs: Additional Tavily parameters

        Returns:
            List of search results
        """
        body = {
            "query": query,
            "api_key": TAVILY_API_KEY,
            **kwargs
        }

        headers = {
            "Content-Type": "application/json"
        }

        try:
            response = requests.post(
                TAVILY_API_BASE_URL,
                json=body,
                headers=headers,
                timeout=15
            )
            response.raise_for_status()
            search_response = response.json()

            results = search_response.get('results', [])
            return results

        except Exception as e:
            print(f"Tavily search error: {e}")
            return []


# Create singleton instance
_enhanced_search = None


def get_enhanced_search() -> EnhancedWebSearch:
    """Get or create singleton instance of EnhancedWebSearch."""
    global _enhanced_search
    if _enhanced_search is None:
        _enhanced_search = EnhancedWebSearch()
    return _enhanced_search


# Main function for backward compatibility
async def enhanced_web_search(
    query: str,
    conversation_history: Optional[List[Dict]] = None,
    **kwargs
):
    """
    Enhanced web search with automatic decision-making.

    This function provides backward compatibility while using the new pipeline.

    Args:
        query: Search query
        conversation_history: Conversation context
        **kwargs: Additional parameters

    Returns:
        str: Generated response
    """
    search = get_enhanced_search()
    result = await search.search_and_answer(query, conversation_history, **kwargs)

    # Return response or indicate that no search was needed
    if result['method'] == 'knowledge':
        return None  # Signal that regular query handler should be used
    else:
        return result['response']
